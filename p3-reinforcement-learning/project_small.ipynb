{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## MO444 Project 3 - Reinforcement Learning\n",
    "\n",
    "* Rodrigo Ara√∫jo Marinho Franco - RA: 233569\n",
    "* Felipe Marinho Tavares - RA: 265680\n",
    "\n",
    "### Contributions:\n",
    "* Rodrigo\n",
    " * ...\n",
    "* Felipe\n",
    " * ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PART I - Evolutionary Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PART II - Reinforcement Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"search/\")\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import environment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SmallClassic Environment - Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state:\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (5, 18, 1)\n",
      "Episode:  100 Average Score: -32.60 Winrate: 0.00%\n",
      "Episode:  200 Average Score: -24.86 Winrate: 0.00%\n",
      "Episode:  300 Average Score: -11.66 Winrate: 0.00%\n",
      "Episode:  400 Average Score: -3.27 Winrate: 0.00%\n",
      "Episode:  500 Average Score: 0.94 Winrate: 0.00%\n",
      "Episode:  600 Average Score: 11.15 Winrate: 0.00%\n",
      "Episode:  700 Average Score: 33.70 Winrate: 1.00%\n",
      "Episode:  800 Average Score: 50.94 Winrate: 0.00%\n",
      "Episode:  900 Average Score: 73.11 Winrate: 0.00%\n",
      "Episode:  1000 Average Score: 96.60 Winrate: 4.00%\n",
      "Episode:  1100 Average Score: 79.16 Winrate: 2.00%\n",
      "Episode:  1200 Average Score: 130.37 Winrate: 5.00%\n",
      "Episode:  1300 Average Score: 125.76 Winrate: 6.00%\n",
      "Episode:  1400 Average Score: 136.85 Winrate: 6.00%\n",
      "Episode:  1500 Average Score: 178.44 Winrate: 12.00%\n",
      "Episode:  1600 Average Score: 175.57 Winrate: 10.00%\n",
      "Episode:  1700 Average Score: 215.34 Winrate: 13.00%\n",
      "Episode:  1800 Average Score: 200.38 Winrate: 13.00%\n",
      "Episode:  1900 Average Score: 251.37 Winrate: 23.00%\n",
      "Episode:  2000 Average Score: 277.90 Winrate: 29.00%\n",
      "Episode:  2100 Average Score: 247.91 Winrate: 27.00%\n",
      "Episode:  2200 Average Score: 323.41 Winrate: 36.00%\n",
      "Episode:  2300 Average Score: 353.06 Winrate: 43.00%\n",
      "Episode:  2400 Average Score: 321.85 Winrate: 37.00%\n",
      "Episode:  2500 Average Score: 343.58 Winrate: 40.00%\n",
      "Episode:  2600 Average Score: 333.90 Winrate: 38.00%\n",
      "Episode:  2700 Average Score: 348.32 Winrate: 43.00%\n",
      "Episode:  2800 Average Score: 403.71 Winrate: 55.00%\n",
      "Episode:  2900 Average Score: 344.14 Winrate: 41.00%\n",
      "Episode:  3000 Average Score: 392.19 Winrate: 52.00%\n",
      "Episode:  3100 Average Score: 399.80 Winrate: 50.00%\n",
      "Episode:  3200 Average Score: 383.96 Winrate: 46.00%\n",
      "Episode:  3300 Average Score: 392.86 Winrate: 50.00%\n",
      "Episode:  3400 Average Score: 353.66 Winrate: 40.00%\n",
      "Episode:  3500 Average Score: 390.42 Winrate: 49.00%\n",
      "Episode:  3600 Average Score: 390.76 Winrate: 49.00%\n",
      "Episode:  3700 Average Score: 397.83 Winrate: 48.00%\n",
      "Episode:  3800 Average Score: 396.06 Winrate: 45.00%\n",
      "Episode:  3900 Average Score: 363.73 Winrate: 45.00%\n",
      "Episode:  4000 Average Score: 388.57 Winrate: 45.00%\n",
      "Episode:  4100 Average Score: 404.03 Winrate: 50.00%\n",
      "Episode:  4200 Average Score: 422.41 Winrate: 49.00%\n",
      "Episode:  4300 Average Score: 428.48 Winrate: 52.00%\n",
      "Episode:  4400 Average Score: 427.18 Winrate: 49.00%\n",
      "Episode:  4500 Average Score: 403.31 Winrate: 48.00%\n",
      "Episode:  4600 Average Score: 426.16 Winrate: 51.00%\n",
      "Episode:  4700 Average Score: 429.01 Winrate: 48.00%\n",
      "Episode:  4800 Average Score: 407.72 Winrate: 44.00%\n",
      "Episode:  4900 Average Score: 379.19 Winrate: 41.00%\n",
      "Episode:  5000 Average Score: 412.33 Winrate: 47.00%\n",
      "Episode:  5100 Average Score: 378.89 Winrate: 41.00%\n",
      "Episode:  5200 Average Score: 431.45 Winrate: 46.00%\n",
      "Episode:  5300 Average Score: 398.85 Winrate: 44.00%\n",
      "Episode:  5400 Average Score: 423.34 Winrate: 45.00%\n",
      "Episode:  5500 Average Score: 402.98 Winrate: 46.00%\n",
      "Episode:  5600 Average Score: 427.58 Winrate: 43.00%\n",
      "Episode:  5700 Average Score: 400.09 Winrate: 43.00%\n",
      "Episode:  5800 Average Score: 385.07 Winrate: 42.00%\n",
      "Episode:  5900 Average Score: 410.02 Winrate: 43.00%\n",
      "Episode:  6000 Average Score: 439.00 Winrate: 47.00%\n",
      "Episode:  6100 Average Score: 395.72 Winrate: 43.00%\n",
      "Episode:  6200 Average Score: 396.21 Winrate: 37.00%\n",
      "Episode:  6300 Average Score: 423.26 Winrate: 45.00%\n",
      "Episode:  6400 Average Score: 401.51 Winrate: 41.00%\n",
      "Episode:  6500 Average Score: 411.52 Winrate: 45.00%\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"buffer_size\": int(1e5),  # replay buffer size\n",
    "    \"batch_size\": 32,        # minibatch size\n",
    "    \"gamma\": 0.99,            # discount factor\n",
    "    \"tau\": 1e-3,              # for soft update of target parameters\n",
    "    \"lr\": 2e-3,               # learning rate\n",
    "    \"weight_decay\": 0.0001,   # Adam parameter\n",
    "    \"update_every\": 10         # how often to update the network\n",
    "}\n",
    "\n",
    "# layouts = smallClassic, mediumClassic, originalClassic\n",
    "env = environment.Environment(params, layout=\"smallClassic\", use_features=True)\n",
    "\n",
    "eps_start = 1.0   # Starting exploration rate\n",
    "eps_end = 0.05    # Minimun exploration rate (0.05 = 5%)\n",
    "eps_decay=0.999\n",
    "n_episodes = 10000\n",
    "print_every = 100 # episodes\n",
    "patience = 10      # max print_every without improvement tolarated\n",
    "checkpoints_without_improvement = 0\n",
    "\n",
    "eps = eps_start\n",
    "best_score = -1000\n",
    "for i_episode in range(1, n_episodes + 1):\n",
    "    env.reset()\n",
    "\n",
    "    while not env.done():\n",
    "        env.step(eps)\n",
    "\n",
    "    eps = max(eps_end, eps_decay*eps)\n",
    "\n",
    "    env.scores.append(env.game.state.getScore())\n",
    "    env.scores_window.append(env.game.state.getScore())\n",
    "\n",
    "    env.wins.append(env.game.state.isWin())\n",
    "    env.wins_window.append(env.game.state.isWin())\n",
    "\n",
    "    average_score = sum(env.scores_window)/float(len(env.scores_window))\n",
    "    winrate = sum(env.wins_window)/float(len(env.wins_window)) * 100.0\n",
    "    env.average_scores.append(average_score)\n",
    "    env.average_wins.append(winrate)\n",
    "\n",
    "    if i_episode % print_every == 0:\n",
    "        print(\"Episode: \", i_episode, end=\" \")\n",
    "        print('Average Score: {:.2f}'.format(average_score), end=\" \")\n",
    "        print('Winrate: {:.2f}%'.format(winrate))\n",
    "\n",
    "        if average_score > best_score:\n",
    "            checkpoints_without_improvement = 0\n",
    "            best_score = average_score\n",
    "            torch.save(env.pacman.qnetwork_local.state_dict(), 'models/checkpoint_small.pth')\n",
    "        else:\n",
    "            checkpoints_without_improvement += 1\n",
    "            if checkpoints_without_improvement == patience:\n",
    "                print(\"Stopping training due to lack of improvement\")\n",
    "                break\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Scores during training\")\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Score')\n",
    "line1, = plt.plot(env.scores)\n",
    "line2, = plt.plot(env.average_scores)\n",
    "plt.legend([line1, line2], [\"Score\", \"Average Score\"])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Wins during training\")\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Number of Wins')\n",
    "line1, = plt.plot(env.average_wins)\n",
    "plt.legend([line1], [\"Average Wins\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-ef6924e5",
   "language": "python",
   "display_name": "PyCharm (p3-reinforcement-learning)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}